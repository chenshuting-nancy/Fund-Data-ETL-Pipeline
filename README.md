# ğŸ“Š Fund Data ETL Pipeline (åŸºé‡‘å•æ•°æ®æå–è‡ªåŠ¨åŒ–)

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Status](https://img.shields.io/badge/Status-Production%20Ready-green)
![Focus](https://img.shields.io/badge/Focus-Finance%20%26%20Automation-orange)

## Project Overview (é¡¹ç›®ç®€ä»‹)

**Fund Data ETL Pipeline** is an automated data processing solution designed to tackle the fragmentation of **daily fund transaction statements** for **investment portfolios** that traditionally require manual entry.
> **é¡¹ç›®èƒŒæ™¯ï¼š** æœ¬é¡¹ç›®æ—¨åœ¨è§£å†³èµ„ç®¡äº§å“ï¼ˆInvestment Portfoliosï¼‰æ¯æ—¥éœ€æ‰‹å·¥å½•å…¥ç¹æ‚åŸºé‡‘å•æ®ï¼ˆTransaction Statementsï¼‰çš„ç—›ç‚¹ã€‚

In the asset management industry, fund transaction data originates from diverse **distribution platforms** (Sales Agencies) with inconsistent formats. This tool serves as a **Unified Data Adaptor**, capable of automatically identifying, extracting, and standardizing data from **20+ distribution platforms** (Banks, Third-party agencies) covering **5 core transaction types** (Subscription, Redemption, Dividend, etc.).
> **æ ¸å¿ƒç—›ç‚¹ï¼š** åœ¨èµ„ç®¡è¡Œä¸šï¼Œäº¤æ˜“æ•°æ®æ¥è‡ªå„ç±»**ä»£é”€æœºæ„/å¹³å°**ï¼Œæ ¼å¼åƒå·®ä¸‡åˆ«ã€‚æœ¬å·¥å…·ä½œä¸ºä¸€ä¸ª**ç»Ÿä¸€æ•°æ®é€‚é…å™¨**ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«ã€æå–å¹¶æ ‡å‡†åŒ–æ¥è‡ª **20+å®¶ä»£é”€æœºæ„** çš„æ•°æ®ï¼Œè¦†ç›– **5ç§æ ¸å¿ƒä¸šåŠ¡ç±»å‹**ï¼ˆç”³è´­ã€èµå›ã€åˆ†çº¢ç­‰ï¼‰ã€‚

**Impact:** This tool transforms a **manual data entry process** that typically takes hours into a sub-minute automated task, ensuring 100% data accuracy for Hundsun valuation systems.
> **é¡¹ç›®æˆæ•ˆï¼š** å°†åŸæœ¬è€—æ—¶æ•°å°æ—¶çš„**æ‰‹å·¥å½•å…¥å•æ®**æµç¨‹è½¬åŒ–ä¸ºåˆ†é’Ÿçº§çš„è‡ªåŠ¨åŒ–ä»»åŠ¡ï¼Œå¹¶ç¡®ä¿æ’ç”Ÿä¼°å€¼ç³»ç»Ÿï¼ˆHundsunï¼‰å…¥åº“æ•°æ®çš„100%å‡†ç¡®ç‡ã€‚

## Key Features (æ ¸å¿ƒåŠŸèƒ½)

* **Multi-Source Compatibility:** Implemented a scalable strategy pattern to handle distinctive formats from 20+ financial institutions (e.g., ICBC, CMB, Alipay, Tiantian Fund, etc.).
* **Intelligent Classification:** Automatically detects document types based on file signatures and naming conventions (e.g., Confirmation Notes, Dividend Statements, Settlement Sheets).
* **Robust Data Cleaning:** Uses Advanced RegEx and Pandas to normalize "dirty data" (merged cells, irregular headers, non-standard date formats).
* **Batch Processing:** Capable of processing hundreds of files locally in seconds, outputting a unified CSV/Excel standard ready for SQL ingestion.

## Tech Stack (æŠ€æœ¯æ ˆ)

* **Core Logic:** Python 3.x
* **Data Manipulation:** Pandas, NumPy
* **File Parsing:** `pdfplumber` (PDF), `openpyxl`/`xlrd` (Excel), `os`/`shutil` (File I/O)
* **Pattern Matching:** Regular Expressions (Re)

## Workflow Architecture (å·¥ä½œæµ)

```mermaid
graph TD
    A[Input Folder: Mixed Raw Files] --> B{File Classifier};
    B -->|Platform A| C[Parser Strategy A];
    B -->|Platform B| D[Parser Strategy B];
    B -->|Platform N...| E[Parser Strategy N];
    C --> F[Data Cleaning & Normalization];
    D --> F;
    E --> F;
    F --> G[Validation Rules];
    G --> H[Output: Standardized Master Data];
```

## Project Structure (é¡¹ç›®ç»“æ„)

```text
Fund-Data-ETL-Pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extractors/       # Specific logic for different banks/platforms
â”‚   â”œâ”€â”€ processors/       # Data cleaning and normalization modules
â”‚   â””â”€â”€ utils/            # Helper functions (File IO, Logger)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/            # Place raw statements here (GitIgnored)
â”‚   â””â”€â”€ output/           # Result files generated here
â”œâ”€â”€ main.py               # Entry point of the application
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md             # Project documentation
```
## Quick Start (å¦‚ä½•è¿è¡Œ)

**Step 1: Clone the repository**
```bash
git clone [https://github.com/chenshuting-nancy/Fund-Data-ETL-Pipeline.git](https://github.com/chenshuting-nancy/Fund-Data-ETL-Pipeline.git)
```
**Step 2.Install dependencies**
```bash
pip install -r requirements.txt
```
**Step 3.Run the pipeline**
Place your raw Excel/PDF files in the data/input folder and run:
```bash
python main.py
```

## Disclaimer (å…è´£å£°æ˜)
This project is a portfolio demonstration. All sensitive business logic, proprietary algorithms, and real financial data have been removed or obfuscated to comply with data privacy regulations. The uploaded code represents the structural framework and general processing logic.

---
### Contact & Availability
* **Author:** Nancy Chen
* **Email:** nancychenshuting@hotmail.com
* **Status:** *Open to freelance opportunities in Financial Automation & Python Development.*
